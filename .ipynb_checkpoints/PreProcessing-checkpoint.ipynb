{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing\n",
    "\n",
    "Now that we have the base layers organized into a base_layers group in the contents frame, we'll use python to iterate through each layer, preparing them to be used in the calculation of the walkscore in the next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import arcpy.mp\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Formatting Fishnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fishnet_layer = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\fishnet_clipped\"\n",
    "base_layers_group = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "output_gdb = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "geodatabase_path = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\output\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field Name: OBJECTID, Field Type: OID\n",
      "Field Name: Shape, Field Type: Geometry\n",
      "Field Name: Shape_Length, Field Type: Double\n",
      "Field Name: Shape_Area, Field Type: Double\n",
      "Field Name: IndexID, Field Type: Integer\n"
     ]
    }
   ],
   "source": [
    "fields = arcpy.ListFields(fishnet_layer)\n",
    "for field in fields:\n",
    "    print(f\"Field Name: {field.name}, Field Type: {field.type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexID field created and populated in fishnet_clipped.\n"
     ]
    }
   ],
   "source": [
    "fishnet_clipped = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\fishnet_clipped\"\n",
    "\n",
    "# Add the IndexID field if it doesn't exist\n",
    "index_field = \"IndexID\"\n",
    "if not any(f.name == index_field for f in arcpy.ListFields(fishnet_clipped)):\n",
    "    arcpy.management.AddField(fishnet_clipped, index_field, \"LONG\")\n",
    "\n",
    "# Populate the IndexID field with unique values\n",
    "with arcpy.da.UpdateCursor(fishnet_clipped, [index_field]) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        row[0] = i + 1\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"IndexID field created and populated in fishnet_clipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers = [\n",
    "    \"Industrial\",\n",
    "    \"ParkingLots\",\n",
    "    \"GolfCourse\",\n",
    "    \"Cemeteries\",\n",
    "    \"Hospitals\",\n",
    "    \"Slope\",\n",
    "    \"Bike_greenways\",\n",
    "    \"Bike_protected\",\n",
    "    \"Bike_buffer\",\n",
    "    \"Healthy_Streets\",\n",
    "    \"Parks\",\n",
    "    \"Universities\",\n",
    "    \"Sidewalks\",\n",
    "    \"Plaza\",\n",
    "    \"trails\",\n",
    "    \"MultiUseTrails\",\n",
    "    \"Streets\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to calculate area\n",
    "def calculate_polygon_area(layer, area_field):\n",
    "    if not any(f.name.lower() == area_field.lower() for f in arcpy.ListFields(layer)):\n",
    "        arcpy.management.AddField(layer, area_field, \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(layer, [[area_field, \"AREA_GEODESIC\"]], area_unit=\"SQUARE_FEET_US\")\n",
    "\n",
    "# Function to calculate area for polylines using recalculated length and width in survey feet\n",
    "def calculate_polyline_area_with_recalculated_length(layer, area_field, width_field):\n",
    "    # Recalculate the length of polylines in survey feet\n",
    "    recalculated_length_field = f\"{area_field}_len\"\n",
    "    if not any(f.name.lower() == recalculated_length_field.lower() for f in arcpy.ListFields(layer)):\n",
    "        arcpy.management.AddField(layer, recalculated_length_field, \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(layer, [[recalculated_length_field, \"LENGTH_GEODESIC\"]], length_unit=\"FEET_US\")\n",
    "\n",
    "    # Calculate the area using the recalculated length and width\n",
    "    if not any(f.name.lower() == area_field.lower() for f in arcpy.ListFields(layer)):\n",
    "        arcpy.management.AddField(layer, area_field, \"DOUBLE\")\n",
    "    with arcpy.da.UpdateCursor(layer, [width_field, recalculated_length_field, area_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            row[2] = row[0] * row[1] if row[0] is not None and row[1] is not None else 0\n",
    "            cursor.updateRow(row)\n",
    "            \n",
    "# # functions used to calculate the street area scaled for speed limit           \n",
    "# def scale_by_speed_limit(speed_limit, decay_rate=0.4):\n",
    "#     # Exponential decay function for scaling by speed limit\n",
    "#     return np.exp(-decay_rate * speed_limit)\n",
    "\n",
    "def calculate_effective_area(layer, effective_area_field, length_field=\"Shape_Length\", width_field=\"street_width\", speed_limit_field=\"SPEEDLIMIT\", at_grade_field=\"at_grade_scalar\"):\n",
    "    # Recalculate the length of polylines in survey feet\n",
    "    recalculated_length_field = f\"{effective_area_field}_len\"\n",
    "    if not any(f.name.lower() == recalculated_length_field.lower() for f in arcpy.ListFields(layer)):\n",
    "        arcpy.management.AddField(layer, recalculated_length_field, \"DOUBLE\")\n",
    "    arcpy.management.CalculateGeometryAttributes(layer, [[recalculated_length_field, \"LENGTH_GEODESIC\"]], length_unit=\"FEET_US\")\n",
    "\n",
    "    # Add a new field for effective area if it does not already exist\n",
    "    if not any(f.name == effective_area_field for f in arcpy.ListFields(layer)):\n",
    "        arcpy.management.AddField(layer, effective_area_field, \"DOUBLE\")\n",
    "\n",
    "    # Calculate effective area: recalculated length * street width * speed limit * at_grade_scalar\n",
    "    with arcpy.da.UpdateCursor(layer, [recalculated_length_field, width_field, speed_limit_field, at_grade_field, effective_area_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is not None and row[1] is not None and row[2] is not None and row[3] is not None:\n",
    "                row[4] = row[0] * row[1] * row[2] * row[3]\n",
    "            else:\n",
    "                row[4] = None\n",
    "            cursor.updateRow(row)\n",
    "    print(f\"Calculated effective area for {layer} and stored in {effective_area_field}.\")\n",
    "    \n",
    "def calculate_average_slope(fishnet_layer, slope_raster, output_table):\n",
    "    arcpy.sa.ZonalStatisticsAsTable(fishnet_layer, \"IndexID\", slope_raster, output_table, \"NODATA\", \"MEAN\")\n",
    "    print(f\"Calculated average slope and stored in {output_table}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\walkscore_fishnet.\n",
      "Copied fishnet_clipped to walkscore_fishnet.\n",
      "Index field populated with unique values.\n",
      "Calculated total area for each fishnet grid cell.\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "arcpy.env.overwriteOutput = True  # Allow outputs to be overwritten\n",
    "\n",
    "fishnet_layer = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\fishnet_clipped\"\n",
    "base_layers_group = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "output_gdb = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "output_folder = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\output\"\n",
    "\n",
    "# Get the spatial reference of the fishnet layer\n",
    "fishnet_sr = arcpy.Describe(fishnet_layer).spatialReference\n",
    "\n",
    "# Define the walkscore_fishnet_layer\n",
    "walkscore_fishnet_layer = f\"{output_gdb}\\\\walkscore_fishnet\"\n",
    "\n",
    "# Check if the walkscore_fishnet_layer exists and delete it if it does\n",
    "if arcpy.Exists(walkscore_fishnet_layer):\n",
    "    arcpy.management.Delete(walkscore_fishnet_layer)\n",
    "    print(f\"Deleted existing {walkscore_fishnet_layer}.\")\n",
    "\n",
    "# Create a copy of the fishnet layer to work on\n",
    "arcpy.management.CopyFeatures(fishnet_layer, walkscore_fishnet_layer)\n",
    "print(\"Copied fishnet_clipped to walkscore_fishnet.\")\n",
    "\n",
    "# Add a new field for indexing and populate it with unique values\n",
    "index_field = \"IndexID\"\n",
    "if not any(f.name == index_field for f in arcpy.ListFields(walkscore_fishnet_layer)):\n",
    "    arcpy.management.AddField(walkscore_fishnet_layer, index_field, \"LONG\")\n",
    "\n",
    "# Populate the new index field with unique values\n",
    "with arcpy.da.UpdateCursor(walkscore_fishnet_layer, [index_field]) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        row[0] = i + 1\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "print(\"Index field populated with unique values.\")\n",
    "\n",
    "# Add a new field for total area if it doesn't exist\n",
    "total_area_field = \"total_area\"\n",
    "if not any(f.name == total_area_field for f in arcpy.ListFields(walkscore_fishnet_layer)):\n",
    "    arcpy.management.AddField(walkscore_fishnet_layer, total_area_field, \"DOUBLE\")\n",
    "\n",
    "# Calculate the total area for each fishnet grid cell\n",
    "arcpy.management.CalculateGeometryAttributes(walkscore_fishnet_layer, [[total_area_field, \"AREA_GEODESIC\"]])\n",
    "print(\"Calculated total area for each fishnet grid cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Process Each Layer and Calculate Allocations for each Fishnet Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Public Amenity Data & Separating Out Amenity Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective Area Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_fields = [sidewalk_score_field, park_score_field, trail_score_field, street_score_field, bike_score_field]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    \"parkinglots\": 15,\n",
    "    \"industrial\": 15,\n",
    "    \"golfcourse\": 5,\n",
    "    \"hospitals\": 1,\n",
    "    \"cemeteries\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Processing Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer: Industrial\n",
      "Processing of areas complete.\n",
      "Processing layer: ParkingLots\n",
      "Processing of areas complete.\n",
      "Processing layer: GolfCourse\n",
      "Processing of areas complete.\n",
      "Processing layer: Cemeteries\n",
      "Processing of areas complete.\n",
      "Processing layer: Hospitals\n",
      "Processing of areas complete.\n",
      "Processing layer: Slope\n",
      "Calculated average slope and stored in C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\Slope_sum.\n",
      "Processing layer: Bike_greenways\n",
      "Processing of areas complete.\n",
      "Processing layer: Bike_protected\n",
      "Processing of areas complete.\n",
      "Processing layer: Bike_buffer\n",
      "Processing of areas complete.\n",
      "Processing layer: Healthy_Streets\n",
      "Processing of areas complete.\n",
      "Processing layer: Parks\n",
      "Processing of areas complete.\n",
      "Processing layer: Universities\n",
      "Processing of areas complete.\n",
      "Processing layer: Sidewalks\n",
      "Processing of areas complete.\n",
      "Processing layer: Plaza\n",
      "Processing of areas complete.\n",
      "Processing layer: trails\n",
      "Processing of areas complete.\n",
      "Processing layer: MultiUseTrails\n",
      "Processing of areas complete.\n",
      "Processing layer: Streets\n",
      "Calculated effective area for C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\Streets_int and stored in Streets_effective_area.\n",
      "Processing of areas complete.\n"
     ]
    }
   ],
   "source": [
    "created_layers = []\n",
    "\n",
    "for layer_name in base_layers:\n",
    "    print(f\"Processing layer: {layer_name}\")  # Debugging statement\n",
    "\n",
    "    # Access the layer\n",
    "    input_layer = f\"{base_layers_group}\\\\{layer_name}\"\n",
    "    \n",
    "    # Verify if the input_layer exists\n",
    "    if not arcpy.Exists(input_layer):\n",
    "        print(f\"Layer {input_layer} does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    if arcpy.Describe(input_layer).dataType == \"RasterDataset\":\n",
    "        # Process the raster layer for slope calculation\n",
    "        slope_output_table = f\"{output_gdb}\\\\Slope_sum\"\n",
    "        calculate_average_slope(walkscore_fishnet_layer, input_layer, slope_output_table)\n",
    "        created_layers.append(slope_output_table)  # Track the created slope table\n",
    "        continue\n",
    "    \n",
    "    # Project the input layer to the same spatial reference as the fishnet layer\n",
    "    input_layer_sr = arcpy.Describe(input_layer).spatialReference\n",
    "    projected_layer = f\"{output_gdb}\\\\{layer_name}_proj\"\n",
    "    \n",
    "    if input_layer_sr.name != fishnet_sr.name:\n",
    "        # Check if the projected layer already exists, and delete if it does\n",
    "        if arcpy.Exists(projected_layer):\n",
    "            arcpy.management.Delete(projected_layer)\n",
    "        arcpy.management.Project(input_layer, projected_layer, fishnet_sr)\n",
    "    else:\n",
    "        projected_layer = input_layer\n",
    "    \n",
    "    # Define the intersect output path\n",
    "    intersect_output = f\"{output_gdb}\\\\{layer_name}_int\"\n",
    "    \n",
    "    # Check if the intersect output already exists, and delete if it does\n",
    "    if arcpy.Exists(intersect_output):\n",
    "        arcpy.management.Delete(intersect_output)\n",
    "    \n",
    "    # Perform Intersect with fishnet\n",
    "    arcpy.analysis.Intersect([walkscore_fishnet_layer, projected_layer], intersect_output)\n",
    "    \n",
    "    # Determine the geometry type of the layer\n",
    "    desc = arcpy.Describe(projected_layer)\n",
    "    geometry_type = desc.shapeType\n",
    "    \n",
    "    # Dynamically generate a unique field name for the area calculation\n",
    "    if layer_name.lower() == \"streets\":\n",
    "        effective_area_field = f\"{layer_name}_effective_area\"\n",
    "        calculate_effective_area(intersect_output, effective_area_field)\n",
    "        area_field = effective_area_field\n",
    "    elif layer_name.lower() in scalers.keys():\n",
    "        area_field = f\"{layer_name}_area\"\n",
    "        area_field = area_field.replace(\"-\", \"_\").replace(\" \", \"_\")\n",
    "        \n",
    "        # Calculate area for polygons\n",
    "        if geometry_type == \"Polygon\":\n",
    "            calculate_polygon_area(intersect_output, area_field)\n",
    "            \n",
    "        # Apply the corresponding scaler to create the effective area\n",
    "        effective_area_field = f\"{layer_name}_effective_area\"\n",
    "        if not any(f.name == effective_area_field for f in arcpy.ListFields(intersect_output)):\n",
    "            arcpy.management.AddField(intersect_output, effective_area_field, \"DOUBLE\")\n",
    "        \n",
    "        scaler = scalers[layer_name.lower()]\n",
    "        with arcpy.da.UpdateCursor(intersect_output, [area_field, effective_area_field]) as cursor:\n",
    "            for row in cursor:\n",
    "                if row[0] is not None:\n",
    "                    row[1] = row[0] * scaler\n",
    "                else:\n",
    "                    row[1] = None\n",
    "                cursor.updateRow(row)\n",
    "        area_field = effective_area_field\n",
    "    else:\n",
    "        area_field = f\"{layer_name}_area\"\n",
    "        area_field = area_field.replace(\"-\", \"_\").replace(\" \", \"_\")  # Sanitize field name\n",
    "        \n",
    "        # Calculate area based on geometry type\n",
    "        if geometry_type == \"Polygon\":\n",
    "            calculate_polygon_area(intersect_output, area_field)\n",
    "        elif geometry_type == \"Polyline\":\n",
    "            # Dynamically find the width field\n",
    "            width_field = None\n",
    "            for field in arcpy.ListFields(intersect_output):\n",
    "                if field.name.lower().endswith(\"width\"):\n",
    "                    width_field = field.name\n",
    "            if width_field:\n",
    "                calculate_polyline_area_with_recalculated_length(intersect_output, area_field, width_field)\n",
    "            else:\n",
    "                print(f\"Width field not found for {layer_name}, skipping area calculation.\")\n",
    "    \n",
    "    # Check if area field was created\n",
    "    if not any(f.name.lower() == area_field.lower() for f in arcpy.ListFields(intersect_output)):\n",
    "        print(f\"Area field {area_field} was not created for {layer_name}, skipping summary statistics.\")\n",
    "        continue\n",
    "    \n",
    "    # Define the summary output path\n",
    "    summary_output = f\"{output_gdb}\\\\{layer_name}_sum\"\n",
    "    \n",
    "    # Check if the summary output already exists, and delete if it does\n",
    "    if arcpy.Exists(summary_output):\n",
    "        arcpy.management.Delete(summary_output)\n",
    "    \n",
    "    # Add IndexID to intersect output if it doesn't exist\n",
    "    if not any(f.name == index_field for f in arcpy.ListFields(intersect_output)):\n",
    "        arcpy.management.AddField(intersect_output, index_field, \"LONG\")\n",
    "        # Populate the IndexID field in intersect output\n",
    "        with arcpy.da.UpdateCursor(intersect_output, [index_field]) as cursor:\n",
    "            for i, row in enumerate(cursor):\n",
    "                row[0] = i + 1\n",
    "                cursor.updateRow(row)\n",
    "\n",
    "    # Calculate Summary Statistics\n",
    "    arcpy.analysis.Statistics(intersect_output, summary_output, [[area_field, \"SUM\"]], index_field)\n",
    "\n",
    "    print(\"Processing of areas complete.\")\n",
    "    created_layers.append(summary_output)  # Track the created summary layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing Slope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Merge the average slope table with the fishnet\n",
    "slope_avg_field = \"AVG_SLOPE\"\n",
    "arcpy.management.JoinField(walkscore_fishnet_layer, index_field, slope_output_table, index_field, slope_avg_field)\n",
    "\n",
    "# # Add the slope field to the list of fields to be normalized and included in the walkscore calculation\n",
    "# norm_fields.append(slope_avg_field)\n",
    "\n",
    "print(\"Slope processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing Point Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique fclass values: 108\n",
      "Unique fclass values:\n",
      "computer_shop\n",
      "theatre\n",
      "bar\n",
      "community_centre\n",
      "clinic\n",
      "ruins\n",
      "gift_shop\n",
      "fountain\n",
      "pub\n",
      "toilet\n",
      "shoe_shop\n",
      "fire_station\n",
      "swimming_pool\n",
      "market_place\n",
      "museum\n",
      "vending_machine\n",
      "video_shop\n",
      "veterinary\n",
      "telephone\n",
      "tower\n",
      "vending_parking\n",
      "comms_tower\n",
      "water_well\n",
      "school\n",
      "picnic_site\n",
      "travel_agent\n",
      "clothes\n",
      "fast_food\n",
      "general\n",
      "sports_shop\n",
      "doctors\n",
      "bench\n",
      "college\n",
      "bicycle_shop\n",
      "atm\n",
      "hostel\n",
      "bakery\n",
      "vending_any\n",
      "furniture_shop\n",
      "florist\n",
      "bookshop\n",
      "viewpoint\n",
      "town_hall\n",
      "car_sharing\n",
      "recycling\n",
      "embassy\n",
      "recycling_paper\n",
      "dog_park\n",
      "cafe\n",
      "cinema\n",
      "newsagent\n",
      "car_dealership\n",
      "guesthouse\n",
      "motel\n",
      "food_court\n",
      "car_wash\n",
      "monument\n",
      "attraction\n",
      "memorial\n",
      "university\n",
      "beverages\n",
      "doityourself\n",
      "recycling_clothes\n",
      "hospital\n",
      "hotel\n",
      "pitch\n",
      "car_rental\n",
      "garden_centre\n",
      "kindergarten\n",
      "optician\n",
      "bank\n",
      "nightclub\n",
      "butcher\n",
      "chemist\n",
      "pharmacy\n",
      "waste_basket\n",
      "hairdresser\n",
      "courthouse\n",
      "artwork\n",
      "shelter\n",
      "playground\n",
      "post_box\n",
      "library\n",
      "tourist_info\n",
      "sports_centre\n",
      "camera_surveillance\n",
      "department_store\n",
      "supermarket\n",
      "greengrocer\n",
      "dentist\n",
      "post_office\n",
      "beauty_shop\n",
      "stationery\n",
      "wastewater_plant\n",
      "mobile_phone_shop\n",
      "arts_centre\n",
      "wayside_shrine\n",
      "drinking_water\n",
      "biergarten\n",
      "bicycle_rental\n",
      "mall\n",
      "laundry\n",
      "restaurant\n",
      "convenience\n",
      "jeweller\n",
      "recycling_glass\n",
      "outdoor_shop\n",
      "toy_shop\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "layer = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\PointsofInterest\"\n",
    "\n",
    "# Use a set to collect unique fclass values\n",
    "fclass_set = set()\n",
    "\n",
    "# Use a SearchCursor to iterate through the fclass field\n",
    "with arcpy.da.SearchCursor(layer, [\"fclass\"]) as cursor:\n",
    "    for row in cursor:\n",
    "        fclass_set.add(row[0])\n",
    "\n",
    "# Print the unique fclass values and their count\n",
    "unique_fclass_count = len(fclass_set)\n",
    "print(f\"Number of unique fclass values: {unique_fclass_count}\")\n",
    "print(\"Unique fclass values:\")\n",
    "for fclass in fclass_set:\n",
    "    print(fclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_amenities = [\n",
    "    'supermarket', 'convenience', 'greengrocer', 'butcher', 'department_store', 'mall', \n",
    "    'gift_shop', 'shoe_shop', 'clothes', 'bookshop', 'stationery', 'furniture_shop', 'jeweller', \n",
    "    'computer_shop', 'mobile_phone_shop', 'outdoor_shop', 'general', 'florist', 'toy_shop',\n",
    "    'beauty_shop', 'laundry', 'bank', 'atm', 'cafe', 'restaurant', \n",
    "    'pub', 'bar', 'fast_food', 'bakery', 'food_court', 'beverages', 'nightclub', 'car_sharing',\n",
    "    'car_wash', 'video_shop', 'vending_any', 'theatre', 'museum', 'attraction', 'cinema',\n",
    "    'market_place', 'mobile_phone_shop', 'bookshop', 'laundry', 'mobile_phone_shop',\n",
    "    'garden_centre','doityourself','hairdresser','bicycle_shop','biergarten','sports_shop'\n",
    "]\n",
    "public_amenities = [\n",
    "    'bench', 'drinking_water', 'waste_basket', 'library', 'post_box','post_office', 'recycling', \n",
    "    'recycling_glass', 'recycling_paper', 'vending_machine', 'artwork', 'tourist_info',\n",
    "    'viewpoint', 'monument', 'picnic_site', 'memorial', 'fountain', 'shelter', 'public_building',\n",
    "    'arts_centre','courthouse','community_centre'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\PointsofInterest\"\n",
    "workspace = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer(input_layer, fclass_list, output_layer_name):\n",
    "    # Create a query to filter the input layer based on fclass values\n",
    "    fclass_query = f\"\"\"fclass IN ({','.join([f\"'{fc}'\" for fc in fclass_list])})\"\"\"\n",
    "    \n",
    "    # Create the output layer\n",
    "    arcpy.management.MakeFeatureLayer(input_layer, \"temp_layer\", fclass_query)\n",
    "    output_layer = f\"{workspace}\\\\{output_layer_name}\"\n",
    "    \n",
    "    # Check if the output layer already exists and delete it if it does\n",
    "    if arcpy.Exists(output_layer):\n",
    "        arcpy.management.Delete(output_layer)\n",
    "    \n",
    "    # Save the filtered features to a new feature class\n",
    "    arcpy.management.CopyFeatures(\"temp_layer\", output_layer)\n",
    "    print(f\"Created {output_layer_name} layer with {len(fclass_list)} fclass values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Business_Amenities layer with 51 fclass values.\n",
      "Created Public_Amenities layer with 22 fclass values.\n",
      "All layers have been created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the Business_Amenities layer\n",
    "create_layer(input_layer, business_amenities, \"Business_Amenities\")\n",
    "\n",
    "# Create the Public_Amenities layer\n",
    "create_layer(input_layer, public_amenities, \"Public_Amenities\")\n",
    "\n",
    "print(\"All layers have been created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "walkscore_fishnet = f\"{workspace}\\\\walkscore_fishnet\"\n",
    "business_amenities_layer = f\"{workspace}\\\\Business_Amenities\"\n",
    "public_amenities_layer = f\"{workspace}\\\\Public_Amenities\"\n",
    "index_field = \"IndexID\"\n",
    "fishnet_area_field = \"Shape_Area\"  # Assuming 'Shape_Area' contains the area of each fishnet cell\n",
    "\n",
    "# Function to calculate density\n",
    "def calculate_density(amenity_layer, density_field, intersect_output, fishnet_layer):\n",
    "    # Intersect the amenity layer with the fishnet\n",
    "    arcpy.analysis.Intersect([amenity_layer, fishnet_layer], intersect_output)\n",
    "    \n",
    "    # Add IndexID to intersect output if it doesn't exist\n",
    "    if not any(f.name == index_field for f in arcpy.ListFields(intersect_output)):\n",
    "        arcpy.management.AddField(intersect_output, index_field, \"LONG\")\n",
    "        # Populate the IndexID field in intersect output\n",
    "        with arcpy.da.UpdateCursor(intersect_output, [index_field]) as cursor:\n",
    "            for i, row in enumerate(cursor):\n",
    "                row[0] = i + 1\n",
    "                cursor.updateRow(row)\n",
    "    \n",
    "    # Calculate the count of points within each fishnet cell\n",
    "    summary_output = f\"{workspace}\\\\{density_field}_sum\"\n",
    "    arcpy.analysis.Statistics(intersect_output, summary_output, [[\"OBJECTID\", \"COUNT\"]], index_field)\n",
    "    \n",
    "    # Join the summary table back to the fishnet layer\n",
    "    arcpy.management.JoinField(fishnet_layer, index_field, summary_output, index_field, [\"COUNT_OBJECTID\"])\n",
    "    \n",
    "    # Calculate density\n",
    "    if not any(f.name == density_field for f in arcpy.ListFields(fishnet_layer)):\n",
    "        arcpy.management.AddField(fishnet_layer, density_field, \"DOUBLE\")\n",
    "    \n",
    "    with arcpy.da.UpdateCursor(fishnet_layer, [\"COUNT_OBJECTID\", fishnet_area_field, density_field]) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] is not None and row[1] is not None and row[1] != 0:\n",
    "                row[2] = row[0] / row[1]  # COUNT_OBJECTID / Shape_Area\n",
    "            else:\n",
    "                row[2] = None\n",
    "            cursor.updateRow(row)\n",
    "    \n",
    "    # Clean up intermediate layers\n",
    "    arcpy.management.Delete(intersect_output)\n",
    "    arcpy.management.Delete(summary_output)\n",
    "    \n",
    "    print(f\"Calculated {density_field} density.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated business_density density.\n",
      "Calculated public_amenity_density density.\n",
      "Calculated business and public amenity densities.\n"
     ]
    }
   ],
   "source": [
    "# Calculate business density\n",
    "calculate_density(business_amenities_layer, \"business_density\", \"business_amenities_intersect\", walkscore_fishnet)\n",
    "# Calculate public amenity density\n",
    "calculate_density(public_amenities_layer, \"public_amenity_density\", \"public_amenities_intersect\", walkscore_fishnet)\n",
    "print(\"Calculated business and public amenity densities.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating an Index Field for walkscore_fishnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the new index field with unique values\n",
    "with arcpy.da.UpdateCursor(walkscore_fishnet_layer, [index_field]) as cursor:\n",
    "    for i, row in enumerate(cursor):\n",
    "        row[0] = i + 1\n",
    "        cursor.updateRow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:  Join Summary Statistic Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted existing summary table\n",
      "Created merged_sums table.\n"
     ]
    }
   ],
   "source": [
    "merged_summary = f\"{output_gdb}\\\\merged_sums\"\n",
    "\n",
    "if arcpy.Exists(merged_summary):\n",
    "    arcpy.management.Delete(merged_summary)\n",
    "    print('deleted existing summary table')\n",
    "    \n",
    "arcpy.management.CreateTable(output_gdb, \"merged_sums\")\n",
    "print(\"Created merged_sums table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated merged summary table created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Add IndexID field to the merged summary table\n",
    "if not any(f.name == index_field for f in arcpy.ListFields(merged_summary)):\n",
    "    arcpy.management.AddField(merged_summary, index_field, \"LONG\")\n",
    "\n",
    "# Create a dictionary to store the aggregated sums\n",
    "aggregated_sums = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "# Iterate through each summary table and aggregate values by IndexID\n",
    "for layer_name in base_layers:\n",
    "    summary_output = f\"{output_gdb}\\\\{layer_name}_sum\"\n",
    "    \n",
    "    # Verify if summary_output exists\n",
    "    if not arcpy.Exists(summary_output):\n",
    "        print(f\"Summary table {summary_output} does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fields = arcpy.ListFields(summary_output)\n",
    "    field_names = [f.name for f in fields if f.name != index_field]\n",
    "    \n",
    "    # Aggregate the summary fields into the dictionary\n",
    "    with arcpy.da.SearchCursor(summary_output, [index_field] + field_names) as cursor:\n",
    "        for row in cursor:\n",
    "            idx = row[0]\n",
    "            for i, field_name in enumerate(field_names):\n",
    "                aggregated_sums[idx][f\"{layer_name}_{field_name}\"] += row[i+1]\n",
    "\n",
    "# Add aggregated fields to the merged summary table\n",
    "for layer_name in base_layers:\n",
    "    summary_output = f\"{output_gdb}\\\\{layer_name}_sum\"\n",
    "    \n",
    "    # Verify if summary_output exists\n",
    "    if not arcpy.Exists(summary_output):\n",
    "        print(f\"Summary table {summary_output} does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    fields = arcpy.ListFields(summary_output)\n",
    "    for field in fields:\n",
    "        if field.name != index_field:\n",
    "            field_name = f\"{layer_name}_{field.name}\"\n",
    "            if not any(f.name == field_name for f in arcpy.ListFields(merged_summary)):\n",
    "                arcpy.management.AddField(merged_summary, field_name, \"DOUBLE\")\n",
    "\n",
    "# Insert the aggregated sums into the merged summary table\n",
    "field_names_to_insert = [index_field] + [f\"{layer_name}_{field.name}\" for layer_name in base_layers for field in arcpy.ListFields(f\"{output_gdb}\\\\{layer_name}_sum\") if field.name != index_field]\n",
    "with arcpy.da.InsertCursor(merged_summary, field_names_to_insert) as cursor:\n",
    "    for idx, fields in aggregated_sums.items():\n",
    "        row = [idx] + [fields.get(field_name, 0) for field_name in field_names_to_insert if field_name != index_field]\n",
    "        cursor.insertRow(row)\n",
    "\n",
    "print(\"Aggregated merged summary table created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verified IndexID in merged_sums.\n"
     ]
    }
   ],
   "source": [
    "merged_summary = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\merged_sums\"\n",
    "\n",
    "# Ensure IndexID exists in merged_sums (this step should already be covered)\n",
    "if not any(f.name == index_field for f in arcpy.ListFields(merged_summary)):\n",
    "    raise ValueError(f\"{index_field} does not exist in {merged_summary}\")\n",
    "\n",
    "print(\"Verified IndexID in merged_sums.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aprx_path = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.aprx\"\n",
    "\n",
    "# aprx = arcpy.mp.ArcGISProject(aprx_path)\n",
    "# map_name = \"Map\"\n",
    "# m = aprx.listMaps(map_name)[0]\n",
    "\n",
    "# # Remove layers from the map's contents pane\n",
    "# for layer in created_layers:\n",
    "#     layer_name = os.path.basename(layer)\n",
    "#     for lyr in m.listLayers():\n",
    "#         if lyr.name == layer_name:\n",
    "#             m.removeLayer(lyr)\n",
    "#             print(f\"Removed layer from map: {lyr.name}\")\n",
    "\n",
    "# # Delete the actual layers\n",
    "# for layer in created_layers:\n",
    "#     if arcpy.Exists(layer):\n",
    "#         arcpy.management.Delete(layer)\n",
    "#         print(f\"Deleted layer: {layer}\")\n",
    "\n",
    "# print(\"Preprocessing complete and temporary layers deleted.\")\n",
    "\n",
    "# # Try to save the project to force a refresh\n",
    "# try:\n",
    "#     aprx.save()\n",
    "#     print(\"Project saved successfully.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Failed to save the project: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Join the Summary Statistics to the Fishnet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields in C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\fishnet_clipped before join:\n",
      "Name: OBJECTID, Type: OID\n",
      "Name: Shape, Type: Geometry\n",
      "Name: Shape_Length, Type: Double\n",
      "Name: Shape_Area, Type: Double\n",
      "Name: IndexID, Type: Integer\n",
      "Fields in C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\merged_sums:\n",
      "Name: OBJECTID, Type: OID\n",
      "Name: IndexID, Type: Integer\n",
      "Name: Industrial_OBJECTID, Type: Double\n",
      "Name: Industrial_FREQUENCY, Type: Double\n",
      "Name: Industrial_SUM_Industrial_effective_area, Type: Double\n",
      "Name: ParkingLots_OBJECTID, Type: Double\n",
      "Name: ParkingLots_FREQUENCY, Type: Double\n",
      "Name: ParkingLots_SUM_ParkingLots_effective_area, Type: Double\n",
      "Name: GolfCourse_OBJECTID, Type: Double\n",
      "Name: GolfCourse_FREQUENCY, Type: Double\n",
      "Name: GolfCourse_SUM_GolfCourse_effective_area, Type: Double\n",
      "Name: Cemeteries_OBJECTID, Type: Double\n",
      "Name: Cemeteries_FREQUENCY, Type: Double\n",
      "Name: Cemeteries_SUM_Cemeteries_effective_area, Type: Double\n",
      "Name: Hospitals_OBJECTID, Type: Double\n",
      "Name: Hospitals_FREQUENCY, Type: Double\n",
      "Name: Hospitals_SUM_Hospitals_effective_area, Type: Double\n",
      "Name: Slope_OBJECTID, Type: Double\n",
      "Name: Slope_COUNT, Type: Double\n",
      "Name: Slope_AREA, Type: Double\n",
      "Name: Slope_MEAN, Type: Double\n",
      "Name: Bike_greenways_OBJECTID, Type: Double\n",
      "Name: Bike_greenways_FREQUENCY, Type: Double\n",
      "Name: Bike_greenways_SUM_Bike_greenways_area, Type: Double\n",
      "Name: Bike_protected_OBJECTID, Type: Double\n",
      "Name: Bike_protected_FREQUENCY, Type: Double\n",
      "Name: Bike_protected_SUM_Bike_protected_area, Type: Double\n",
      "Name: Bike_buffer_OBJECTID, Type: Double\n",
      "Name: Bike_buffer_FREQUENCY, Type: Double\n",
      "Name: Bike_buffer_SUM_Bike_buffer_area, Type: Double\n",
      "Name: Healthy_Streets_OBJECTID, Type: Double\n",
      "Name: Healthy_Streets_FREQUENCY, Type: Double\n",
      "Name: Healthy_Streets_SUM_Healthy_Streets_area, Type: Double\n",
      "Name: Parks_OBJECTID, Type: Double\n",
      "Name: Parks_FREQUENCY, Type: Double\n",
      "Name: Parks_SUM_Parks_area, Type: Double\n",
      "Name: Universities_OBJECTID, Type: Double\n",
      "Name: Universities_FREQUENCY, Type: Double\n",
      "Name: Universities_SUM_Universities_area, Type: Double\n",
      "Name: Sidewalks_OBJECTID, Type: Double\n",
      "Name: Sidewalks_FREQUENCY, Type: Double\n",
      "Name: Sidewalks_SUM_Sidewalks_area, Type: Double\n",
      "Name: Plaza_OBJECTID, Type: Double\n",
      "Name: Plaza_FREQUENCY, Type: Double\n",
      "Name: Plaza_SUM_Plaza_area, Type: Double\n",
      "Name: trails_OBJECTID, Type: Double\n",
      "Name: trails_FREQUENCY, Type: Double\n",
      "Name: trails_SUM_trails_area, Type: Double\n",
      "Name: MultiUseTrails_OBJECTID, Type: Double\n",
      "Name: MultiUseTrails_FREQUENCY, Type: Double\n",
      "Name: MultiUseTrails_SUM_MultiUseTrails_area, Type: Double\n",
      "Name: Streets_OBJECTID, Type: Double\n",
      "Name: Streets_FREQUENCY, Type: Double\n",
      "Name: Streets_SUM_Streets_effective_area, Type: Double\n",
      "Join operation completed successfully using JoinField.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fields in {fishnet_layer} before join:\")\n",
    "fields = arcpy.ListFields(fishnet_layer)\n",
    "for field in fields:\n",
    "    print(f\"Name: {field.name}, Type: {field.type}\")\n",
    "\n",
    "# Verify fields in merged_summary before joining\n",
    "print(f\"Fields in {merged_summary}:\")\n",
    "fields = arcpy.ListFields(merged_summary)\n",
    "for field in fields:\n",
    "    print(f\"Name: {field.name}, Type: {field.type}\")\n",
    "\n",
    "# Use JoinField to permanently add the fields from merged_summary to walkscore_fishnet_layer\n",
    "try:\n",
    "    arcpy.management.JoinField(walkscore_fishnet_layer, \"IndexID\", merged_summary, \"IndexID\")\n",
    "    print(\"Join operation completed successfully using JoinField.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during join: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fields in C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\\walkscore_fishnet after join with merged summary:\n",
      "Name: OBJECTID, Type: OID\n",
      "Name: Shape, Type: Geometry\n",
      "Name: IndexID, Type: Integer\n",
      "Name: Shape_Length, Type: Double\n",
      "Name: Shape_Area, Type: Double\n",
      "Name: total_area, Type: Double\n",
      "Name: COUNT_OBJECTID, Type: Integer\n",
      "Name: business_density, Type: Double\n",
      "Name: COUNT_OBJECTID_1, Type: Integer\n",
      "Name: public_amenity_density, Type: Double\n",
      "Name: IndexID_1, Type: Integer\n",
      "Name: Industrial_OBJECTID, Type: Double\n",
      "Name: Industrial_FREQUENCY, Type: Double\n",
      "Name: Industrial_SUM_Industrial_effective_area, Type: Double\n",
      "Name: ParkingLots_OBJECTID, Type: Double\n",
      "Name: ParkingLots_FREQUENCY, Type: Double\n",
      "Name: ParkingLots_SUM_ParkingLots_effective_area, Type: Double\n",
      "Name: GolfCourse_OBJECTID, Type: Double\n",
      "Name: GolfCourse_FREQUENCY, Type: Double\n",
      "Name: GolfCourse_SUM_GolfCourse_effective_area, Type: Double\n",
      "Name: Cemeteries_OBJECTID, Type: Double\n",
      "Name: Cemeteries_FREQUENCY, Type: Double\n",
      "Name: Cemeteries_SUM_Cemeteries_effective_area, Type: Double\n",
      "Name: Hospitals_OBJECTID, Type: Double\n",
      "Name: Hospitals_FREQUENCY, Type: Double\n",
      "Name: Hospitals_SUM_Hospitals_effective_area, Type: Double\n",
      "Name: Slope_OBJECTID, Type: Double\n",
      "Name: Slope_COUNT, Type: Double\n",
      "Name: Slope_AREA, Type: Double\n",
      "Name: Slope_MEAN, Type: Double\n",
      "Name: Bike_greenways_OBJECTID, Type: Double\n",
      "Name: Bike_greenways_FREQUENCY, Type: Double\n",
      "Name: Bike_greenways_SUM_Bike_greenways_area, Type: Double\n",
      "Name: Bike_protected_OBJECTID, Type: Double\n",
      "Name: Bike_protected_FREQUENCY, Type: Double\n",
      "Name: Bike_protected_SUM_Bike_protected_area, Type: Double\n",
      "Name: Bike_buffer_OBJECTID, Type: Double\n",
      "Name: Bike_buffer_FREQUENCY, Type: Double\n",
      "Name: Bike_buffer_SUM_Bike_buffer_area, Type: Double\n",
      "Name: Healthy_Streets_OBJECTID, Type: Double\n",
      "Name: Healthy_Streets_FREQUENCY, Type: Double\n",
      "Name: Healthy_Streets_SUM_Healthy_Streets_area, Type: Double\n",
      "Name: Parks_OBJECTID, Type: Double\n",
      "Name: Parks_FREQUENCY, Type: Double\n",
      "Name: Parks_SUM_Parks_area, Type: Double\n",
      "Name: Universities_OBJECTID, Type: Double\n",
      "Name: Universities_FREQUENCY, Type: Double\n",
      "Name: Universities_SUM_Universities_area, Type: Double\n",
      "Name: Sidewalks_OBJECTID, Type: Double\n",
      "Name: Sidewalks_FREQUENCY, Type: Double\n",
      "Name: Sidewalks_SUM_Sidewalks_area, Type: Double\n",
      "Name: Plaza_OBJECTID, Type: Double\n",
      "Name: Plaza_FREQUENCY, Type: Double\n",
      "Name: Plaza_SUM_Plaza_area, Type: Double\n",
      "Name: trails_OBJECTID, Type: Double\n",
      "Name: trails_FREQUENCY, Type: Double\n",
      "Name: trails_SUM_trails_area, Type: Double\n",
      "Name: MultiUseTrails_OBJECTID, Type: Double\n",
      "Name: MultiUseTrails_FREQUENCY, Type: Double\n",
      "Name: MultiUseTrails_SUM_MultiUseTrails_area, Type: Double\n",
      "Name: Streets_OBJECTID, Type: Double\n",
      "Name: Streets_FREQUENCY, Type: Double\n",
      "Name: Streets_SUM_Streets_effective_area, Type: Double\n",
      "\n",
      "Joined fields: ['merged_sums.OBJECTID', 'merged_sums.Industrial_OBJECTID', 'merged_sums.Industrial_FREQUENCY', 'merged_sums.Industrial_SUM_Industrial_effective_area', 'merged_sums.ParkingLots_OBJECTID', 'merged_sums.ParkingLots_FREQUENCY', 'merged_sums.ParkingLots_SUM_ParkingLots_effective_area', 'merged_sums.GolfCourse_OBJECTID', 'merged_sums.GolfCourse_FREQUENCY', 'merged_sums.GolfCourse_SUM_GolfCourse_effective_area', 'merged_sums.Cemeteries_OBJECTID', 'merged_sums.Cemeteries_FREQUENCY', 'merged_sums.Cemeteries_SUM_Cemeteries_effective_area', 'merged_sums.Hospitals_OBJECTID', 'merged_sums.Hospitals_FREQUENCY', 'merged_sums.Hospitals_SUM_Hospitals_effective_area', 'merged_sums.Slope_OBJECTID', 'merged_sums.Slope_COUNT', 'merged_sums.Slope_AREA', 'merged_sums.Slope_MEAN', 'merged_sums.Bike_greenways_OBJECTID', 'merged_sums.Bike_greenways_FREQUENCY', 'merged_sums.Bike_greenways_SUM_Bike_greenways_area', 'merged_sums.Bike_protected_OBJECTID', 'merged_sums.Bike_protected_FREQUENCY', 'merged_sums.Bike_protected_SUM_Bike_protected_area', 'merged_sums.Bike_buffer_OBJECTID', 'merged_sums.Bike_buffer_FREQUENCY', 'merged_sums.Bike_buffer_SUM_Bike_buffer_area', 'merged_sums.Healthy_Streets_OBJECTID', 'merged_sums.Healthy_Streets_FREQUENCY', 'merged_sums.Healthy_Streets_SUM_Healthy_Streets_area', 'merged_sums.Parks_OBJECTID', 'merged_sums.Parks_FREQUENCY', 'merged_sums.Parks_SUM_Parks_area', 'merged_sums.Universities_OBJECTID', 'merged_sums.Universities_FREQUENCY', 'merged_sums.Universities_SUM_Universities_area', 'merged_sums.Sidewalks_OBJECTID', 'merged_sums.Sidewalks_FREQUENCY', 'merged_sums.Sidewalks_SUM_Sidewalks_area', 'merged_sums.Plaza_OBJECTID', 'merged_sums.Plaza_FREQUENCY', 'merged_sums.Plaza_SUM_Plaza_area', 'merged_sums.trails_OBJECTID', 'merged_sums.trails_FREQUENCY', 'merged_sums.trails_SUM_trails_area', 'merged_sums.MultiUseTrails_OBJECTID', 'merged_sums.MultiUseTrails_FREQUENCY', 'merged_sums.MultiUseTrails_SUM_MultiUseTrails_area', 'merged_sums.Streets_OBJECTID', 'merged_sums.Streets_FREQUENCY', 'merged_sums.Streets_SUM_Streets_effective_area']\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFields in {walkscore_fishnet_layer} after join with merged summary:\")\n",
    "fields = arcpy.ListFields(walkscore_fishnet_layer)\n",
    "for field in fields:\n",
    "    print(f\"Name: {field.name}, Type: {field.type}\")\n",
    "\n",
    "# Ensure the joined fields are included in the final export\n",
    "joined_fields = [f\"{merged_summary.split(os.sep)[-1]}.{f.name}\" for f in arcpy.ListFields(merged_summary) if f.name != \"IndexID\"]\n",
    "print(f\"\\nJoined fields: {joined_fields}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Cleaning Walkscore Fishnet\n",
    "\n",
    "Finally, we'll take the fishnet (walkscore_fishnet) and trim the fields down to only the mandatory fields (and permanent fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "walkscore_fishnet = f\"{output_gdb}\\\\walkscore_fishnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified fields\n",
    "fields_to_drop = []\n",
    "for field in arcpy.ListFields(walkscore_fishnet):\n",
    "    if field.name.endswith(\"FREQUENCY\") or field.name.endswith(\"_OBJECTID\") or field.name.endswith(\"Slope_AREA\") or field.name.endswith(\"Slope_COUNT\") or field.name.endswith(\"IndexID_1\"):\n",
    "        fields_to_drop.append(field.name)\n",
    "\n",
    "if fields_to_drop:\n",
    "    arcpy.management.DeleteField(walkscore_fishnet, fields_to_drop)\n",
    "\n",
    "# Verify fields in walkscore_fishnet after dropping specified fields\n",
    "walkscore_fishnet = f\"{output_gdb}\\\\walkscore_fishnet\"\n",
    "print(f\"\\nFields in {walkscore_fishnet} after dropping specified fields:\")\n",
    "fields = arcpy.ListFields(walkscore_fishnet)\n",
    "for field in fields:\n",
    "    print(f\"Name: {field.name}, Type: {field.type}\")\n",
    "\n",
    "print(\"Fields dropped successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Cleaning Contents Pane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_created_layers(layers_list):\n",
    "    for layer in layers_list:\n",
    "        if arcpy.Exists(layer):\n",
    "            arcpy.management.Delete(layer)\n",
    "            print(f\"Deleted layer: {layer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # At the end of your script, delete the created layers\n",
    "# delete_created_layers(created_layers)\n",
    "\n",
    "# print(\"All created layers have been deleted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers = [\n",
    "    \"Industrial\",\n",
    "    \"ParkingLots\",\n",
    "    \"GolfCourse\",\n",
    "    \"Cemeteries\",\n",
    "    \"Hospitals\",\n",
    "#     \"Slope\",\n",
    "    \"Bike_greenways\",\n",
    "    \"Bike_protected\",\n",
    "    \"Bike_buffer\",\n",
    "    \"Healthy_Streets\",\n",
    "    \"Parks\",\n",
    "    \"Universities\",\n",
    "    \"Sidewalks\",\n",
    "    \"Plaza\",\n",
    "    \"trails\",\n",
    "    \"MultiUseTrails\",\n",
    "    \"Streets\",\n",
    "    \"fishnet_clipped\",\n",
    "    \"Marked_Crosswalks\",\n",
    "    \"fishnet_clipped\",\n",
    "    \"neighborhoods\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers_group = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "target_spatial_reference = arcpy.SpatialReference(3857)  # WGS 1984 Web Mercator (auxiliary sphere)\n",
    "\n",
    "def project_layer(input_layer, target_sr):\n",
    "    input_layer_sr = arcpy.Describe(input_layer).spatialReference\n",
    "    \n",
    "    if input_layer_sr.name != target_sr.name:\n",
    "        temp_projected_layer = os.path.join(arcpy.env.scratchGDB, f\"{os.path.basename(input_layer)}_proj\")\n",
    "        arcpy.management.Project(input_layer, temp_projected_layer, target_sr)\n",
    "        print(f\"Projected {input_layer} to {temp_projected_layer}.\")\n",
    "        \n",
    "        # Overwrite the original layer with the projected version\n",
    "        arcpy.management.Delete(input_layer)\n",
    "        arcpy.management.CopyFeatures(temp_projected_layer, input_layer)\n",
    "        arcpy.management.Delete(temp_projected_layer)\n",
    "        print(f\"Replaced original {input_layer} with projected version.\")\n",
    "    else:\n",
    "        print(f\"{input_layer} is already in the target spatial reference.\")\n",
    "\n",
    "\n",
    "# Process each base layer\n",
    "for layer_name in base_layers:\n",
    "    print(f\"Processing layer: {layer_name}\")  # Debugging statement\n",
    "\n",
    "    # Access the layer\n",
    "    input_layer = f\"{base_layers_group}\\\\{layer_name}\"\n",
    "    \n",
    "    # Verify if the input_layer exists\n",
    "    if not arcpy.Exists(input_layer):\n",
    "        print(f\"Layer {input_layer} does not exist. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Project the input layer to the target spatial reference\n",
    "    project_layer(input_layer, target_spatial_reference)\n",
    "\n",
    "print(\"All layers have been projected to the target spatial reference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arcpy.env.workspace = r\"C:\\Users\\rtvpd\\OneDrive\\Documentos\\ArcGIS\\Projects\\Walkability_Seattle\\Walkability_Seattle.gdb\"\n",
    "# arcpy.env.overwriteOutput = True  # Allow outputs to be overwritten\n",
    "\n",
    "# # List of raster layers to reproject\n",
    "# raster_layers = [\"Slope\"]  # Replace with your raster layer names\n",
    "\n",
    "# # Target spatial reference (WGS 1984)\n",
    "# target_sr = arcpy.SpatialReference(3857)  # WKID for WGS 1984 Web Mercator (auxiliary sphere)\n",
    "\n",
    "# # Loop through each raster layer and reproject it\n",
    "# for raster_name in raster_layers:\n",
    "#     input_raster = f\"{arcpy.env.workspace}\\\\{raster_name}\"\n",
    "#     output_raster = f\"{arcpy.env.workspace}\\\\{raster_name}_reprojected\"\n",
    "    \n",
    "#     # Check if the input raster is already in the target spatial reference\n",
    "#     raster_sr = arcpy.Describe(input_raster).spatialReference\n",
    "#     if raster_sr.name == target_sr.name:\n",
    "#         print(f\"{input_raster} is already in the target spatial reference.\")\n",
    "#         continue\n",
    "    \n",
    "#     # Reproject the raster to WGS 1984\n",
    "#     arcpy.management.ProjectRaster(in_raster=input_raster, \n",
    "#                                    out_raster=output_raster, \n",
    "#                                    out_coor_system=target_sr,\n",
    "#                                    resampling_type=\"NEAREST\")  # Change resampling type as needed\n",
    "\n",
    "#     # Delete the original raster and rename the reprojected raster to the original name\n",
    "#     arcpy.management.Delete(input_raster)\n",
    "#     arcpy.management.Rename(output_raster, input_raster)\n",
    "    \n",
    "#     print(f\"Reprojected {raster_name} to WGS 1984 Web Mercator (auxiliary sphere)4.\")\n",
    "\n",
    "# print(\"All rasters reprojected to WGS 1984 Web Mercator (auxiliary sphere).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
